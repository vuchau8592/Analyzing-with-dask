This project is a groupwork with 2 members (Shree and me) for the cleaning, tidying, and analyzing with a big dataset with Dask.

In this project, we will be working with dask library on a over 1.5GB dataset. The goal is to extract as mush as information we can.

This dataset contains scheduled and actual departure and arrival times reported by certified U.S. air carriers that account for at least one percent of domestic scheduled passenger revenues. The data is collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS).

Our working dataset will cover all the flights from January 2019 to September 2020 for all U.S region, which is the latest date that has available data.

The dataset can be acessed at: https://www.transtats.bts.gov/

In this project, several method of data cleaning and visualization will be used such as:
- Using dask for big dataset
- Several method to handle missing value and outlier such as IQR...
- Using plotly to visualize the information obtains from analyzing
- etc...
